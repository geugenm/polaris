"""
Module to launch anomaly data analysis.
"""
import logging
import os

from polaris.anomaly.anomaly_detector import AnomalyDetector
from polaris.anomaly.anomaly_detector_configurator import \
    AnomalyDetectorConfigurator
from polaris.anomaly.anomaly_output import AnomalyOutput
from polaris.data.readers import read_polaris_data
from polaris.learn.analysis import NoFramesInInputFile

LOGGER = logging.getLogger(__name__)


class FileIsADirectory(Exception):
    """Raised when the file path is of a directory
    """


# pylint: disable-msg=too-many-arguments


def behave(input_file,
           output_file="/tmp/anomaly_output.json",
           detector_config_file=None,
           cache_dir='/tmp',
           metrics_dir='/tmp',
           csv_sep=',',
           save_test_train_data=False):
    """
    Detect events in input data and output anomaly events

        :param input_file: CSV or JSON file path that will be
            converted to a dataframe
        :type input_file: str

        :param output_file: Output file path for the generated graph.
            It will overwrite if the file already exists. Defaults to None,
            which is'/tmp/polaris_graph.json'
        :type output_file: str, optional

        :param detector_config_file: Detector configuration file path,
            defaults to None. Refer to CrossCorrelationConfigurator for
            the default parameters
        :type detector_config_file: str, optional

        :param cache_dir: directory to store files such as models used,
            normalizer, training data
        :type cache_dir: str

        :param metrics_dir: directory to store anomaly metrics
        :type metrics_dir: str

        :param csv_sep: The character that separates the columns inside of
            the CSV file, defaults to ','
        :type csv_sep: str, optional

        :param save_test_train_data: decides weather to save test and
            train data in cache or not
        :type save_test_train_data: Boolean

        :raises NoFramesInInputFile: If there are no frames in the converted
            dataframe
    """
    if os.path.isdir(output_file):
        LOGGER.error("output file path is a directory")
        raise FileIsADirectory

    if not os.path.isfile(input_file):
        LOGGER.error("Input file not found")
        raise FileNotFoundError

    metadata, dataframe = read_polaris_data(input_file, csv_sep)

    if dataframe.empty:
        LOGGER.error("Empty list of frames -- nothing to learn from!")
        raise NoFramesInInputFile

    #  getting parameters for anomaly detector
    anomaly_config = AnomalyDetectorConfigurator(
        detector_configuration_file=detector_config_file)
    anomaly_params = anomaly_config.get_configuration()

    # creating detector and detecting events
    detector = AnomalyDetector(dataset_metadata=metadata,
                               anomaly_detector_params=anomaly_params)
    anomaly_metrics = detector.train_predict_output(data=dataframe)

    # saving data generated by detector
    detector.save_all(cache_dir, save_test_train_data)

    # save metrics generated by detector
    detector.save_anomaly_metrics(metrics_dir, anomaly_metrics)

    output = AnomalyOutput(metadata=metadata)
    output.from_detector(detector=detector)

    save_output_file(output_file, output.to_json())


def save_output_file(output_file, json_data):
    """
    Function to save output json file.
    :param output_file: path of output file to write
    :type output_file: str
    :param json_data: json data to write
    :type json_data: dict
    """
    parent_dir = os.path.dirname(output_file)
    if not os.path.isdir(parent_dir):
        try:
            os.makedirs(parent_dir)
        except Exception as err:
            LOGGER.error(
                "Error creating the path %s."
                "Do you have the correct permissions?", str(parent_dir))
            LOGGER.critical(err)
            raise err
    with open(output_file, 'w') as graph_file:
        graph_file.write(json_data)
